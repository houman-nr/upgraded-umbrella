{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8343753,"sourceType":"datasetVersion","datasetId":4956094},{"sourceId":11060340,"sourceType":"datasetVersion","datasetId":6891279},{"sourceId":11060490,"sourceType":"datasetVersion","datasetId":6891391},{"sourceId":11071177,"sourceType":"datasetVersion","datasetId":6899194},{"sourceId":11071186,"sourceType":"datasetVersion","datasetId":6899199}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:21:29.813598Z","iopub.execute_input":"2025-07-05T18:21:29.813869Z","iopub.status.idle":"2025-07-05T18:23:01.938240Z","shell.execute_reply.started":"2025-07-05T18:21:29.813845Z","shell.execute_reply":"2025-07-05T18:23:01.937295Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"#### General library importation and variable initialization","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom itertools import zip_longest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:23:01.939927Z","iopub.execute_input":"2025-07-05T18:23:01.940227Z","iopub.status.idle":"2025-07-05T18:23:38.048693Z","shell.execute_reply.started":"2025-07-05T18:23:01.940195Z","shell.execute_reply":"2025-07-05T18:23:38.048167Z"}},"outputs":[{"name":"stderr","text":"2025-07-05 18:23:22.023236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751739802.445992      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751739802.567949      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"EPOCH = 16\nBATCH_SIZE = 64\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/mt5-small\"\nSEED = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:23:38.049244Z","iopub.execute_input":"2025-07-05T18:23:38.049673Z","iopub.status.idle":"2025-07-05T18:23:38.053478Z","shell.execute_reply.started":"2025-07-05T18:23:38.049654Z","shell.execute_reply":"2025-07-05T18:23:38.052686Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def set_seed():\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\nset_seed()\ntokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:23:38.056210Z","iopub.execute_input":"2025-07-05T18:23:38.056549Z","iopub.status.idle":"2025-07-05T18:23:59.925208Z","shell.execute_reply.started":"2025-07-05T18:23:38.056522Z","shell.execute_reply":"2025-07-05T18:23:59.923978Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2efda13841ed482babc507afee2b8824"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15c559b9197470d90c595e6e57450bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392645c50506442495cc8271e100c6e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75c1a9ba316c4673aad2f8bb1924d745"}},"metadata":{}},{"name":"stderr","text":"You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7a9706224a45ffbecd1f2bfa7b58cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30aaf9dc4d4d4819a2e5888351ae00f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c8cc60e782946fc80ea4e5f0b6d2262"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"#### Reading data from datasets and Data cleaning tasks","metadata":{}},{"cell_type":"code","source":"mapping = {\n    2: 'very good',\n    1: 'good',\n    0: 'neutral',\n    -1: 'bad',\n    -2: 'very bad'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:23:59.926430Z","iopub.execute_input":"2025-07-05T18:23:59.927047Z","iopub.status.idle":"2025-07-05T18:23:59.937640Z","shell.execute_reply.started":"2025-07-05T18:23:59.927007Z","shell.execute_reply":"2025-07-05T18:23:59.936658Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def dataStructured(ds):\n    ds.columns = ['review', 'category']\n    ds['category'] = ds['category'].replace(mapping).astype(str)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:23:59.938392Z","iopub.execute_input":"2025-07-05T18:23:59.938692Z","iopub.status.idle":"2025-07-05T18:24:01.597191Z","shell.execute_reply.started":"2025-07-05T18:23:59.938664Z","shell.execute_reply":"2025-07-05T18:24:01.596439Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"original_ds  = dataStructured(pd.read_csv('/kaggle/input/original-sentipers/original.csv'))\ntest_ds      = dataStructured(pd.read_csv('/kaggle/input/test-sentipers/test.csv'))\nbalanced_ds  = dataStructured(pd.read_csv('/kaggle/input/balanced-sentipers/balanced.csv'))\ntranslated_ds= dataStructured(pd.read_csv('/kaggle/input/translation-sentipers/translation.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:01.598202Z","iopub.execute_input":"2025-07-05T18:24:01.598417Z","iopub.status.idle":"2025-07-05T18:24:02.746778Z","shell.execute_reply.started":"2025-07-05T18:24:01.598400Z","shell.execute_reply":"2025-07-05T18:24:02.745931Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"#### Fine-Tuning requirements for the specified model","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        review = self.data['review'].iloc[idx]\n        category = self.data['category'].iloc[idx]\n        \n        # tokenizing input review\n        review_encoding = self.tokenizer(review, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        \n        # tokenizing category\n        category_encoding = self.tokenizer(category, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            # agent review\n            'review_input_id': review_encoding['input_ids'].squeeze(),\n            'review_attention_mask': review_encoding['attention_mask'].squeeze(),\n            # category\n            'category_id': category_encoding['input_ids'].squeeze(),\n            'category_mask': category_encoding['attention_mask'].squeeze()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:02.747603Z","iopub.execute_input":"2025-07-05T18:24:02.747896Z","iopub.status.idle":"2025-07-05T18:24:03.297325Z","shell.execute_reply.started":"2025-07-05T18:24:02.747858Z","shell.execute_reply":"2025-07-05T18:24:03.296538Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Defining the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:03.298023Z","iopub.execute_input":"2025-07-05T18:24:03.298295Z","iopub.status.idle":"2025-07-05T18:24:04.473206Z","shell.execute_reply.started":"2025-07-05T18:24:03.298272Z","shell.execute_reply":"2025-07-05T18:24:04.471954Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def calculateF1(prediction_list, actual_list):\n    # Flatten lists if needed (if you've accidentally appended lists instead of values)\n    if isinstance(prediction_list[0], list):\n        prediction_list = [item for sublist in prediction_list for item in sublist]\n    if isinstance(actual_list[0], list):\n        actual_list = [item for sublist in actual_list for item in sublist]\n    \n    assert len(prediction_list) == len(actual_list), \"Length mismatch between predictions and actuals\"\n\n    try:\n        f1 = f1_score(actual_list, prediction_list, average='macro')  # or 'weighted' depending on class balance\n    except Exception as e:\n        print(f\"Error calculating F1: {e}\")\n        f1 = 0.0\n    \n    return f1\n\ndef evaluateModel(model, dataLoader, tokenizer):\n    model.eval()\n    actual_list, prediction_list = [], []\n\n    with torch.no_grad():\n        for batch in dataLoader:\n            ids = batch['review_input_id']\n            mask = batch['review_attention_mask']\n            output_id = batch['category_id']\n\n            actuals = tokenizer.batch_decode(output_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n            generated_output = model.generate(input_ids=ids, attention_mask=mask, max_length=64)\n            preds = tokenizer.batch_decode(generated_output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n\n            actual_list.extend(actuals)  # Make sure clear_data returns a list of strings/labels\n            prediction_list.extend(preds)\n\n    return calculateF1(prediction_list, actual_list)\n\ndef trainModel(model, data_loader, vDataLoader, tokenizer, optimizer, EPOCH):\n    for epoch in range(EPOCH):\n        model.train()\n        losses = []\n\n        for batch in data_loader:\n            review_input = batch['review_input_id']\n            review_attention_mask = batch['review_attention_mask']\n            category_id = batch['category_id']\n\n            optimizer.zero_grad()\n\n            output = model(input_ids=review_input, attention_mask=review_attention_mask, labels=category_id)\n            loss = output.loss\n            losses.append(loss.item())\n\n            loss.backward()\n            optimizer.step()\n        \n        f1 = evaluateModel(model, vDataLoader, tokenizer)\n        print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f} - Avg Loss: {sum(losses)/len(losses):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:04.475899Z","iopub.execute_input":"2025-07-05T18:24:04.476215Z","iopub.status.idle":"2025-07-05T18:24:05.223087Z","shell.execute_reply.started":"2025-07-05T18:24:04.476194Z","shell.execute_reply":"2025-07-05T18:24:05.222296Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Shuffle and split\noriginal_ds = original_ds.sample(frac = 1, random_state = SEED).reset_index(drop=True)\n\nval_size = int(len(original_ds) * 0.15)\nvalidation_ds = original_ds.iloc[:val_size]\ntrain_ds = original_ds.iloc[val_size:]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:05.223949Z","iopub.execute_input":"2025-07-05T18:24:05.224233Z","iopub.status.idle":"2025-07-05T18:24:06.354069Z","shell.execute_reply.started":"2025-07-05T18:24:05.224210Z","shell.execute_reply":"2025-07-05T18:24:06.353162Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Create a data loader for TRAIN dataframe\ntrain_dataset = CustomDataset(train_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntrain_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# Create a data loader for EVALUATION dataframe\nval_dataset = CustomDataset(validation_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nval_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# Create a data loader for TEST dataframe\ntest_dataset = CustomDataset(test_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntest_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:06.355213Z","iopub.execute_input":"2025-07-05T18:24:06.355554Z","iopub.status.idle":"2025-07-05T18:24:07.049865Z","shell.execute_reply.started":"2025-07-05T18:24:06.355528Z","shell.execute_reply":"2025-07-05T18:24:07.049200Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"trainModel(model, train_data_loader, val_data_loader, tokenizer, optimizer, EPOCH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T18:24:07.050462Z","iopub.execute_input":"2025-07-05T18:24:07.050695Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - F1 Score: 0.0000 - Avg Loss: 36.5294\nEpoch 2 - F1 Score: 0.0000 - Avg Loss: 20.3523\nEpoch 3 - F1 Score: 0.0000 - Avg Loss: 12.6095\nEpoch 4 - F1 Score: 0.0000 - Avg Loss: 7.2957\n","output_type":"stream"}],"execution_count":null}]}