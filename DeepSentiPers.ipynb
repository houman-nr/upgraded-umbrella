{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8343753,"sourceType":"datasetVersion","datasetId":4956094},{"sourceId":11060340,"sourceType":"datasetVersion","datasetId":6891279},{"sourceId":11060490,"sourceType":"datasetVersion","datasetId":6891391},{"sourceId":11071177,"sourceType":"datasetVersion","datasetId":6899194},{"sourceId":11071186,"sourceType":"datasetVersion","datasetId":6899199}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:20:59.770197Z","iopub.execute_input":"2025-06-08T10:20:59.770517Z","iopub.status.idle":"2025-06-08T10:21:05.683810Z","shell.execute_reply.started":"2025-06-08T10:20:59.770487Z","shell.execute_reply":"2025-06-08T10:21:05.682935Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"#### General library importation and variable initialization","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom itertools import zip_longest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:21:05.685263Z","iopub.execute_input":"2025-06-08T10:21:05.685582Z","iopub.status.idle":"2025-06-08T10:21:37.423694Z","shell.execute_reply.started":"2025-06-08T10:21:05.685550Z","shell.execute_reply":"2025-06-08T10:21:37.423021Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"EPOCH = 32\nBATCH_SIZE = 64\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/flan-t5-small\"\nSEED = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:21:37.424896Z","iopub.execute_input":"2025-06-08T10:21:37.425472Z","iopub.status.idle":"2025-06-08T10:21:37.429113Z","shell.execute_reply.started":"2025-06-08T10:21:37.425446Z","shell.execute_reply":"2025-06-08T10:21:37.428324Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def set_seed():\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\nset_seed()\ntokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:21:37.430376Z","iopub.execute_input":"2025-06-08T10:21:37.430666Z","iopub.status.idle":"2025-06-08T10:21:41.631553Z","shell.execute_reply.started":"2025-06-08T10:21:37.430636Z","shell.execute_reply":"2025-06-08T10:21:41.630822Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f943045ca14a1eba2f5c1b433a4521"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(â€¦)a5b18a05535c9e14c7a355904270e15b0945ea86:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07682d86ca6243ae874484b801b9b93c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c3eba8acc504195a07324e8dc076238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"554cccfd900242af8a8049909893ec5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"068ab1d7aedf47848f1f50f6d17f2827"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe2ae9f37ad49be89b93d356bc74135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9187cb59ea944880aaca2203ce0d71c1"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"#### Reading data from datasets and Data cleaning tasks","metadata":{}},{"cell_type":"code","source":"def dataStructured(ds):\n    ds.columns = ['review', 'category']\n    ds['category'] = ds['category'].astype(str)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:21:41.632399Z","iopub.execute_input":"2025-06-08T10:21:41.632610Z","iopub.status.idle":"2025-06-08T10:21:41.636281Z","shell.execute_reply.started":"2025-06-08T10:21:41.632592Z","shell.execute_reply":"2025-06-08T10:21:41.635578Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"original_ds  = dataStructured(pd.read_csv('/kaggle/input/original-sentipers/original.csv'))\ntest_ds      = dataStructured(pd.read_csv('/kaggle/input/test-sentipers/test.csv'))\nbalanced_ds  = dataStructured(pd.read_csv('/kaggle/input/balanced-sentipers/balanced.csv'))\ntranslated_ds= dataStructured(pd.read_csv('/kaggle/input/translation-sentipers/translation.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:21:41.636991Z","iopub.execute_input":"2025-06-08T10:21:41.637251Z","iopub.status.idle":"2025-06-08T10:21:41.852227Z","shell.execute_reply.started":"2025-06-08T10:21:41.637232Z","shell.execute_reply":"2025-06-08T10:21:41.851297Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"#### Fine-Tuning requirements for the specified model","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        review = self.data['review'].iloc[idx]\n        category = self.data['category'].iloc[idx]\n        \n        # tokenizing input review\n        review_encoding = self.tokenizer(review, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        \n        # tokenizing category\n        category_encoding = self.tokenizer(category, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            # agent review\n            'review_input_id': review_encoding['input_ids'].squeeze(),\n            'review_attention_mask': review_encoding['attention_mask'].squeeze(),\n            # category\n            'category_id': category_encoding['input_ids'].squeeze(),\n            'category_mask': category_encoding['attention_mask'].squeeze()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:22:58.356845Z","iopub.execute_input":"2025-06-08T10:22:58.357207Z","iopub.status.idle":"2025-06-08T10:22:58.363640Z","shell.execute_reply.started":"2025-06-08T10:22:58.357175Z","shell.execute_reply":"2025-06-08T10:22:58.362751Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Defining the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:22:59.164772Z","iopub.execute_input":"2025-06-08T10:22:59.165070Z","iopub.status.idle":"2025-06-08T10:22:59.169900Z","shell.execute_reply.started":"2025-06-08T10:22:59.165027Z","shell.execute_reply":"2025-06-08T10:22:59.169137Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def calculateF1(prediction_list, actual_list):\n    # Flatten lists if needed (if you've accidentally appended lists instead of values)\n    if isinstance(prediction_list[0], list):\n        prediction_list = [item for sublist in prediction_list for item in sublist]\n    if isinstance(actual_list[0], list):\n        actual_list = [item for sublist in actual_list for item in sublist]\n    \n    assert len(prediction_list) == len(actual_list), \"Length mismatch between predictions and actuals\"\n\n    try:\n        f1 = f1_score(actual_list, prediction_list, average='macro')  # or 'weighted' depending on class balance\n    except Exception as e:\n        print(f\"Error calculating F1: {e}\")\n        f1 = 0.0\n    \n    return f1\n\ndef evaluateModel(model, dataLoader, tokenizer):\n    model.eval()\n    actual_list, prediction_list = [], []\n\n    with torch.no_grad():\n        for batch in dataLoader:\n            ids = batch['review_input_id']\n            mask = batch['review_attention_mask']\n            output_id = batch['category_id']\n\n            actuals = tokenizer.batch_decode(output_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n            generated_output = model.generate(input_ids=ids, attention_mask=mask, max_length=64)\n            preds = tokenizer.batch_decode(generated_output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n\n            actual_list.extend(actuals)  # Make sure clear_data returns a list of strings/labels\n            prediction_list.extend(preds)\n\n    return calculateF1(prediction_list, actual_list)\n\ndef trainModel(model, data_loader, vDataLoader, tokenizer, optimizer, EPOCH):\n    for epoch in range(EPOCH):\n        model.train()\n        losses = []\n\n        for batch in data_loader:\n            review_input = batch['review_input_id']\n            review_attention_mask = batch['review_attention_mask']\n            category_id = batch['category_id']\n\n            optimizer.zero_grad()\n\n            output = model(input_ids=review_input, attention_mask=review_attention_mask, labels=category_id)\n            loss = output.loss\n            losses.append(loss.item())\n\n            loss.backward()\n            optimizer.step()\n        \n        f1 = evaluateModel(model, vDataLoader, tokenizer)\n        print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f} - Avg Loss: {sum(losses)/len(losses):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:22:59.922968Z","iopub.execute_input":"2025-06-08T10:22:59.923281Z","iopub.status.idle":"2025-06-08T10:22:59.931405Z","shell.execute_reply.started":"2025-06-08T10:22:59.923256Z","shell.execute_reply":"2025-06-08T10:22:59.930465Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Shuffle and split\noriginal_ds = original_ds.sample(frac = 1, random_state = SEED).reset_index(drop=True)\n\nval_size = int(len(original_ds) * 0.15)\nvalidation_ds = original_ds.iloc[:val_size]\ntrain_ds = original_ds.iloc[val_size:]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:23:04.390987Z","iopub.execute_input":"2025-06-08T10:23:04.391364Z","iopub.status.idle":"2025-06-08T10:23:04.400133Z","shell.execute_reply.started":"2025-06-08T10:23:04.391336Z","shell.execute_reply":"2025-06-08T10:23:04.399343Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Create a data loader for TRAIN dataframe\ntrain_dataset = CustomDataset(train_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntrain_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# Create a data loader for EVALUATION dataframe\nval_dataset = CustomDataset(validation_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nval_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# Create a data loader for TEST dataframe\ntest_dataset = CustomDataset(test_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntest_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:23:06.066349Z","iopub.execute_input":"2025-06-08T10:23:06.066654Z","iopub.status.idle":"2025-06-08T10:23:06.072080Z","shell.execute_reply.started":"2025-06-08T10:23:06.066630Z","shell.execute_reply":"2025-06-08T10:23:06.071014Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"trainModel(model, train_data_loader, val_data_loader, tokenizer, optimizer, EPOCH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T10:23:07.690534Z","iopub.execute_input":"2025-06-08T10:23:07.690832Z","iopub.status.idle":"2025-06-08T10:38:13.560849Z","shell.execute_reply.started":"2025-06-08T10:23:07.690808Z","shell.execute_reply":"2025-06-08T10:38:13.559869Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - F1 Score: 0.1290 - Avg Loss: 1.0519\nEpoch 2 - F1 Score: 0.1561 - Avg Loss: 0.1682\nEpoch 3 - F1 Score: 0.1290 - Avg Loss: 0.1665\nEpoch 4 - F1 Score: 0.1925 - Avg Loss: 0.1637\nEpoch 5 - F1 Score: 0.1991 - Avg Loss: 0.1599\nEpoch 6 - F1 Score: 0.1290 - Avg Loss: 0.1592\nEpoch 7 - F1 Score: 0.1749 - Avg Loss: 0.1587\nEpoch 8 - F1 Score: 0.1290 - Avg Loss: 0.1593\nEpoch 9 - F1 Score: 0.1290 - Avg Loss: 0.1630\nEpoch 10 - F1 Score: 0.1290 - Avg Loss: 0.1598\nEpoch 11 - F1 Score: 0.1290 - Avg Loss: 0.1591\nEpoch 12 - F1 Score: 0.1740 - Avg Loss: 0.1597\nEpoch 13 - F1 Score: 0.1789 - Avg Loss: 0.1596\nEpoch 14 - F1 Score: 0.1911 - Avg Loss: 0.1604\nEpoch 15 - F1 Score: 0.1288 - Avg Loss: 0.1584\nEpoch 16 - F1 Score: 0.1290 - Avg Loss: 0.1597\nEpoch 17 - F1 Score: 0.1290 - Avg Loss: 0.1587\nEpoch 18 - F1 Score: 0.1290 - Avg Loss: 0.1864\nEpoch 19 - F1 Score: 0.1290 - Avg Loss: 0.2205\nEpoch 20 - F1 Score: 0.1290 - Avg Loss: 0.1638\nEpoch 21 - F1 Score: 0.1290 - Avg Loss: 0.1760\nEpoch 22 - F1 Score: 0.1290 - Avg Loss: 0.1630\nEpoch 23 - F1 Score: 0.1290 - Avg Loss: 0.1628\nEpoch 24 - F1 Score: 0.1290 - Avg Loss: 0.1641\nEpoch 25 - F1 Score: 0.1290 - Avg Loss: 0.1629\nEpoch 26 - F1 Score: 0.1290 - Avg Loss: 0.1617\nEpoch 27 - F1 Score: 0.1290 - Avg Loss: 0.1612\nEpoch 28 - F1 Score: 0.1290 - Avg Loss: 0.1609\nEpoch 29 - F1 Score: 0.1290 - Avg Loss: 0.1604\nEpoch 30 - F1 Score: 0.1290 - Avg Loss: 0.1608\nEpoch 31 - F1 Score: 0.1290 - Avg Loss: 0.1604\nEpoch 32 - F1 Score: 0.1290 - Avg Loss: 0.1605\n","output_type":"stream"}],"execution_count":19}]}