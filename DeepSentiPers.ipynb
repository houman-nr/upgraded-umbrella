{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8343753,"sourceType":"datasetVersion","datasetId":4956094},{"sourceId":11060340,"sourceType":"datasetVersion","datasetId":6891279},{"sourceId":11060490,"sourceType":"datasetVersion","datasetId":6891391},{"sourceId":11071177,"sourceType":"datasetVersion","datasetId":6899194},{"sourceId":11071186,"sourceType":"datasetVersion","datasetId":6899199}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:40:31.028371Z","iopub.execute_input":"2025-07-04T22:40:31.028791Z","iopub.status.idle":"2025-07-04T22:40:38.972832Z","shell.execute_reply.started":"2025-07-04T22:40:31.028745Z","shell.execute_reply":"2025-07-04T22:40:38.971833Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"#### General library importation and variable initialization","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom itertools import zip_longest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:40:38.974271Z","iopub.execute_input":"2025-07-04T22:40:38.974642Z","iopub.status.idle":"2025-07-04T22:41:13.441244Z","shell.execute_reply.started":"2025-07-04T22:40:38.974610Z","shell.execute_reply":"2025-07-04T22:41:13.440573Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"EPOCH = 32\nBATCH_SIZE = 64\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/flan-t5-small\"\nSEED = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:13.442532Z","iopub.execute_input":"2025-07-04T22:41:13.443082Z","iopub.status.idle":"2025-07-04T22:41:13.446992Z","shell.execute_reply.started":"2025-07-04T22:41:13.443057Z","shell.execute_reply":"2025-07-04T22:41:13.446274Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def set_seed():\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\nset_seed()\ntokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:13.447959Z","iopub.execute_input":"2025-07-04T22:41:13.448256Z","iopub.status.idle":"2025-07-04T22:41:17.218187Z","shell.execute_reply.started":"2025-07-04T22:41:13.448227Z","shell.execute_reply":"2025-07-04T22:41:17.217531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6395f1c356c1425499e658d57ba2a92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(â€¦)a5b18a05535c9e14c7a355904270e15b0945ea86:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dfed2c6cf58433491b6e1bb406a9669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f38d0f3bca4f26ab2ef6aa0180cd01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"624a50c580fc49c18e179bc861da93b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6121f978e34cf7bce4fea50d665db1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1523c915c5044c492348329cace80db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2011e5e672ce4caaa3b72573a45492ed"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"#### Reading data from datasets and Data cleaning tasks","metadata":{}},{"cell_type":"code","source":"mapping = {\n    2: 'very good',\n    1: 'good',\n    0: 'neutral',\n    -1: 'bad',\n    -2: 'very bad'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.218940Z","iopub.execute_input":"2025-07-04T22:41:17.219180Z","iopub.status.idle":"2025-07-04T22:41:17.223431Z","shell.execute_reply.started":"2025-07-04T22:41:17.219141Z","shell.execute_reply":"2025-07-04T22:41:17.222519Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def dataStructured(ds):\n    ds.columns = ['review', 'category']\n    ds['category'] = ds['category'].replace(mapping).astype(str)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.224328Z","iopub.execute_input":"2025-07-04T22:41:17.224673Z","iopub.status.idle":"2025-07-04T22:41:17.318823Z","shell.execute_reply.started":"2025-07-04T22:41:17.224639Z","shell.execute_reply":"2025-07-04T22:41:17.318072Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"original_ds  = dataStructured(pd.read_csv('/kaggle/input/original-sentipers/original.csv'))\ntest_ds      = dataStructured(pd.read_csv('/kaggle/input/test-sentipers/test.csv'))\nbalanced_ds  = dataStructured(pd.read_csv('/kaggle/input/balanced-sentipers/balanced.csv'))\ntranslated_ds= dataStructured(pd.read_csv('/kaggle/input/translation-sentipers/translation.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.319720Z","iopub.execute_input":"2025-07-04T22:41:17.319960Z","iopub.status.idle":"2025-07-04T22:41:17.584880Z","shell.execute_reply.started":"2025-07-04T22:41:17.319939Z","shell.execute_reply":"2025-07-04T22:41:17.583826Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"#### Fine-Tuning requirements for the specified model","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        review = self.data['review'].iloc[idx]\n        category = self.data['category'].iloc[idx]\n        \n        # tokenizing input review\n        review_encoding = self.tokenizer(review, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        \n        # tokenizing category\n        category_encoding = self.tokenizer(category, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            # agent review\n            'review_input_id': review_encoding['input_ids'].squeeze(),\n            'review_attention_mask': review_encoding['attention_mask'].squeeze(),\n            # category\n            'category_id': category_encoding['input_ids'].squeeze(),\n            'category_mask': category_encoding['attention_mask'].squeeze()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.587653Z","iopub.execute_input":"2025-07-04T22:41:17.587916Z","iopub.status.idle":"2025-07-04T22:41:17.594124Z","shell.execute_reply.started":"2025-07-04T22:41:17.587895Z","shell.execute_reply":"2025-07-04T22:41:17.593341Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Defining the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.595251Z","iopub.execute_input":"2025-07-04T22:41:17.595552Z","iopub.status.idle":"2025-07-04T22:41:17.616168Z","shell.execute_reply.started":"2025-07-04T22:41:17.595520Z","shell.execute_reply":"2025-07-04T22:41:17.615533Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def calculateF1(prediction_list, actual_list):\n    # Flatten lists if needed (if you've accidentally appended lists instead of values)\n    if isinstance(prediction_list[0], list):\n        prediction_list = [item for sublist in prediction_list for item in sublist]\n    if isinstance(actual_list[0], list):\n        actual_list = [item for sublist in actual_list for item in sublist]\n    \n    assert len(prediction_list) == len(actual_list), \"Length mismatch between predictions and actuals\"\n\n    try:\n        f1 = f1_score(actual_list, prediction_list, average='macro')  # or 'weighted' depending on class balance\n    except Exception as e:\n        print(f\"Error calculating F1: {e}\")\n        f1 = 0.0\n    \n    return f1\n\ndef evaluateModel(model, dataLoader, tokenizer):\n    model.eval()\n    actual_list, prediction_list = [], []\n\n    with torch.no_grad():\n        for batch in dataLoader:\n            ids = batch['review_input_id']\n            mask = batch['review_attention_mask']\n            output_id = batch['category_id']\n\n            actuals = tokenizer.batch_decode(output_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n            generated_output = model.generate(input_ids=ids, attention_mask=mask, max_length=64)\n            preds = tokenizer.batch_decode(generated_output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n\n            actual_list.extend(actuals)  # Make sure clear_data returns a list of strings/labels\n            prediction_list.extend(preds)\n\n    return calculateF1(prediction_list, actual_list)\n\ndef trainModel(model, data_loader, vDataLoader, tokenizer, optimizer, EPOCH):\n    for epoch in range(EPOCH):\n        model.train()\n        losses = []\n\n        for batch in data_loader:\n            review_input = batch['review_input_id']\n            review_attention_mask = batch['review_attention_mask']\n            category_id = batch['category_id']\n\n            optimizer.zero_grad()\n\n            output = model(input_ids=review_input, attention_mask=review_attention_mask, labels=category_id)\n            loss = output.loss\n            losses.append(loss.item())\n\n            loss.backward()\n            optimizer.step()\n        \n        f1 = evaluateModel(model, vDataLoader, tokenizer)\n        print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f} - Avg Loss: {sum(losses)/len(losses):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.617036Z","iopub.execute_input":"2025-07-04T22:41:17.617306Z","iopub.status.idle":"2025-07-04T22:41:17.634249Z","shell.execute_reply.started":"2025-07-04T22:41:17.617273Z","shell.execute_reply":"2025-07-04T22:41:17.633397Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Shuffle and split\noriginal_ds = original_ds.sample(frac = 1, random_state = SEED).reset_index(drop=True)\n\nval_size = int(len(original_ds) * 0.15)\nvalidation_ds = original_ds.iloc[:val_size]\ntrain_ds = original_ds.iloc[val_size:]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.635127Z","iopub.execute_input":"2025-07-04T22:41:17.635351Z","iopub.status.idle":"2025-07-04T22:41:17.674938Z","shell.execute_reply.started":"2025-07-04T22:41:17.635331Z","shell.execute_reply":"2025-07-04T22:41:17.673987Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Create a data loader for TRAIN dataframe\ntrain_dataset = CustomDataset(train_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntrain_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# Create a data loader for EVALUATION dataframe\nval_dataset = CustomDataset(validation_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nval_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# Create a data loader for TEST dataframe\ntest_dataset = CustomDataset(test_ds, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntest_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.675887Z","iopub.execute_input":"2025-07-04T22:41:17.676189Z","iopub.status.idle":"2025-07-04T22:41:17.691654Z","shell.execute_reply.started":"2025-07-04T22:41:17.676157Z","shell.execute_reply":"2025-07-04T22:41:17.690806Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"trainModel(model, train_data_loader, val_data_loader, tokenizer, optimizer, EPOCH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T22:41:17.692483Z","iopub.execute_input":"2025-07-04T22:41:17.692726Z","iopub.status.idle":"2025-07-04T22:56:14.509185Z","shell.execute_reply.started":"2025-07-04T22:41:17.692707Z","shell.execute_reply":"2025-07-04T22:56:14.508170Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - F1 Score: 0.1472 - Avg Loss: 1.1682\nEpoch 2 - F1 Score: 0.1677 - Avg Loss: 0.1678\nEpoch 3 - F1 Score: 0.1981 - Avg Loss: 0.1648\nEpoch 4 - F1 Score: 0.1723 - Avg Loss: 0.1639\nEpoch 5 - F1 Score: 0.1725 - Avg Loss: 0.1617\nEpoch 6 - F1 Score: 0.1970 - Avg Loss: 0.1612\nEpoch 7 - F1 Score: 0.1894 - Avg Loss: 0.1591\nEpoch 8 - F1 Score: 0.1799 - Avg Loss: 0.1596\nEpoch 9 - F1 Score: 0.1968 - Avg Loss: 0.1582\nEpoch 10 - F1 Score: 0.1748 - Avg Loss: 0.1586\nEpoch 11 - F1 Score: 0.1802 - Avg Loss: 0.1580\nEpoch 12 - F1 Score: 0.1851 - Avg Loss: 0.1553\nEpoch 13 - F1 Score: 0.1490 - Avg Loss: 0.1554\nEpoch 14 - F1 Score: 0.1997 - Avg Loss: 0.1566\nEpoch 15 - F1 Score: 0.2004 - Avg Loss: 0.1577\nEpoch 16 - F1 Score: 0.1804 - Avg Loss: 0.1610\nEpoch 17 - F1 Score: 0.1229 - Avg Loss: 0.1606\nEpoch 18 - F1 Score: 0.1229 - Avg Loss: 0.1589\nEpoch 19 - F1 Score: 0.1229 - Avg Loss: 0.1593\nEpoch 20 - F1 Score: 0.1229 - Avg Loss: 0.1596\nEpoch 21 - F1 Score: 0.1227 - Avg Loss: 0.1596\nEpoch 22 - F1 Score: 0.1323 - Avg Loss: 0.1623\nEpoch 23 - F1 Score: 0.1229 - Avg Loss: 0.1606\nEpoch 24 - F1 Score: 0.1229 - Avg Loss: 0.1598\nEpoch 25 - F1 Score: 0.1272 - Avg Loss: 0.1591\nEpoch 26 - F1 Score: 0.1229 - Avg Loss: 0.1587\nEpoch 27 - F1 Score: 0.1229 - Avg Loss: 0.1589\nEpoch 28 - F1 Score: 0.1229 - Avg Loss: 0.1590\nEpoch 29 - F1 Score: 0.1229 - Avg Loss: 0.1589\nEpoch 30 - F1 Score: 0.1353 - Avg Loss: 0.1583\nEpoch 31 - F1 Score: 0.1908 - Avg Loss: 0.1580\nEpoch 32 - F1 Score: 0.1286 - Avg Loss: 0.1573\n","output_type":"stream"}],"execution_count":13}]}